---
title: "TimeVaryingDetection_mrmr"
output: html_document
date: "2024-11-12"
---

# Mrmr Model Comparison

**Classic mrmr model** (fixed detection probability)

vs.

**Custom mrmr model** (independent, time-varying detection probabilities)

## Introduction

The R package mrmr serves as an interface to prepare data and run population models. It relies on a site-specific multi-state Bayesian open-population Jolly-Seber CMR model (hereafter referred to as the multi-state model) for the mathematical and computational part of model fitting.The multi-state model is written in the Stan programming language, which is designed for probabilistic modeling and Bayesian inference. The 'changes to mrmr' outlined in this report are primarily changes to the multi-state model, via modifications to the Stan code. The Stan code is not included in this report. Instead, changes are described using the English language. Snippets of essential Stan code are provided, when necessary, in *italics*, following the format (*classic model code*) —\> (*custom model code*).

The multi-state model is composed of seven blocks:

1.  Functions - handle repeated calculations. Key functions are forward_prob( ) and partial_sum_lpmf( ).

2.  Data - specifies input data.

3.  Transformed Data

4.  **Parameters** - declared the parameters the model will estimate.

5.  **Transformed parameters**

6.  Model - defines the statistical model and specifies the priors.

7.  **Generated quantities** - calculates quantities after the model is fit, used for interpretation and diagnostics.

This report focuses on changes made to three of those blocks: generates quantities, parameters, and transformed parameters. Those changes, and their functionality, are outlined below.

### Generated Quantities Block

Both the classic and custom models include changes to the generated quantities block of mrmr's underlying Stan model. The generated quantities block is composed of post-hoc computations based on the model's parameters after it has finished fitting the data. Changes to this block do not affect how the model runs or the estimated parameter values. The generated quantities blocks of both the custom and classic model are identical. Generated quantities include:

1.  N - total abundance, estimated for each primary period.

2.  B - number of adults recruited into the population, estimated for each primary period.

3.  p - detection probability, estimated for each session (secondary period). In the classic model, p is fixed so the estimate is identical for each session. In the custom model, p is estimated independently for each session (time-varying detection probabilities).

4.  phi_est - survival probability, estimated between primary periods for the whole population. phi_est[1] is the collective estimated survival probability between the first and second primary periods, phi_est[2] between the second and third, and so on.\*

    -   \*I need to confirm my suspicion that the model generates "boundary estimates" for phi (an estimate before the first primary period, and after the last primary period). I am currently operating under this assumption. If I can't confirm this by myself, maybe I can ask Max.

5.  log_lik - log of the likelihood, calculated for each individual, real and pseudo. Likelihood is the probability of observing an individual's capture history given the model parameters. Pseudo-individuals don't actually have a capture histories, so their log_lik values are all identical. See the 'Compare Model Fit' section of this report for more information about this quantity.

### Parameters Block

(*vector[m_detect] beta_detect;*) —\> (*vector[Jtot] beta_detect;*)

This change is essential to achieving independent, time-varying estimates of detection probability in the custom model.

**beta_detect** is a vector of parameters that represent the logit-scale detection probability for survey sessions. The classic mrmr model defines beta_detect as a vector of size m_detect. m_detect refers to the number of detection covariates. The custom model defines beta_detect as a vector of size Jtot. Jtot refers to the total number of survey sessions. Each entry in the vector now corresponds to a specific survey session (custom) rather than a covariate (classic).

Meaning is assigned to beta_detect in the functions block via the transformed parameter logit_detect, within the forward_prob( ) function. No changes were made to this function.

### Transformed Parameters Block

(*logit_detect = X_detect \* beta_detect;*) —\> (*logit_detect = beta_detect;*)

In the classic model, logit_detect is derived from beta_detect using the design matrix of covariates x_detect. This ties detection probabilities to shared covariates. In the custom model, logit_detect is assigned directly to beta_detect, making each session's detection probability independent.

Changes to the parameters and transformed parameters blocks reflect a purpose to obtain the most accurate estimates of N, B, p, and phi for the collective population. The classic model reflect a purpose to model detection and survival by covariates, which makes sense in the context of Knapp and Joseph (2018). If and when I want to introduce covariates into my analysis, I will need to revisit this section. (I'm not sure if it is possible to include both covariates in the design matrix and indepentent, session-specific detection.)

## The Data

This analysis uses capture-mark-recapture (CMR) data for a population of endangered Sierra Nevada yellow-legged frogs (*Rana sierrae*) in the Sierra National Forest, California. This population is referred to by the numeric site id of its associated water body, 54188. The data set is publicly available from the Mountain Lakes Research Group.

## Analysis

This section describes the analysis performed to compare the classic and custom models. Both models were fit to the same capture-mark-recapture (CMR) data for the Sierra Nevada yellow-legged frog population at site 54188. Key comparisons include estimates of population abundance (N), recruitment (B), detection probability (p), and survival (phi). To evaluate model performance, I used the **leave-one-out cross-validation (LOO)** method, which assesses model fit while penalizing complexity.

The goal of this analysis is to determine whether the custom model, with independent, time-varying estimates of detection probability, provides a significantly better fit to the data compared to the classic model, which assumes detection probability is constant across sessions. Differences in model performance will be interpreted using the LOO expected log predictive density (ELPD) values, along with associated uncertainty estimates.

Results and interpretations for each parameter and the overall model comparison are detailed in the following subsections.

**Load packages**

```{r}
library(cmdstanr)
library(mrmr)
library(ggpubr)
library(dplyr)
```

### Prepare data

Load data for population 54188 and format it with mrmr's clean_data( ) function.

```{r}
# set local paths for 54188 captures and surveys
captures <- read.csv("/Users/johnimperato/Desktop/Mossy-Pond/data/54188_capture.csv")  
surveys <- read.csv("/Users/johnimperato/Desktop/Mossy-Pond/data/54188_survey.csv")   

# clean data
data_54188 <- mrmr::clean_data(captures, surveys)
```

### Fit the Custom Model

```{r}
# Fit the custom model using the modified function
custom_mod_54188 <- fit_model_custom(data_54188,
                                chains = 3, 
                                iter_sampling = 1000, 
                                iter_warmup = 400)

# create and view model summary
custom_mod_54188_summary <- custom_mod_54188$m_fit$summary()
View(custom_mod_54188_summary)

# save results to .csv file
write.csv(custom_mod_54188_summary, "54188_custom_mod_summary")

```

**Plot abundance and recruitment**

...with mrmr's built-in plotting functionality.

```{r}
trapdoor_custom_abundance_plot <- mrmr::plot_model(custom_mod_54188, "abundance")
trapdoor_custom_recruitment_plot <- mrmr::plot_model(custom_mod_54188, "recruitment")

# arrange plots 
mrmr_custom_plots_54188 <- ggarrange(trapdoor_custom_abundance_plot, trapdoor_custom_recruitment_plot, ncol =1)

# add title
custom_annotated <- annotate_figure(mrmr_custom_plots_54188, top = text_grob("Time-Varying Detection mrmr", size = 14, face = "bold"))
```

### Fit the classic model

```{r}
# Fit the model using mrmr's built in function
classic_mod_54188 <- fit_model_classic_loglik(data_54188,
                                chains = 3, 
                                iter_sampling = 1000, 
                                iter_warmup = 400)

# create and view summary
classic_mod_54188_summary <- classic_mod_54188$m_fit$summary()
View(classic_mod_54188_summary)

# save summary to .csv file
write.csv(classic_mod_54188_summary, "54188_classic_mod_summary.csv")

```

**Plot abundance and recruitment**

...with mrmr's built-in plotting functionality.

```{r}
trapdoor_classic_abundance_plot <- mrmr::plot_model(classic_mod_54188, "abundance")
trapdoor_classic_recruitment_plot <- mrmr::plot_model(classic_mod_54188, "recruitment")

# arrange plots
mrmr_classic_plots_54188 <- ggarrange(trapdoor_classic_abundance_plot, trapdoor_classic_recruitment_plot, ncol =1)

# add title
classic_annotated <- annotate_figure(mrmr_classic_plots_54188, top = text_grob("Classic mrmr", size = 14, face = "bold"))

```

### Model Comparison

#### Generated Quantities

**Create a table comparing the mean generated quantity values for each model**

This table shows **only the mean** estimated value for each generated quantity. It is meant to serve as a quick reference for comparing model output. See the individual model summaries for complete generated quantity summaries.

```{r}
# pull quantities from model fit summary
N_classic <- classic_mod_54188_summary[4216:4220, 1:2]
N_custom <- custom_mod_54188_summary[4229:4233, 1:2]
B_classic <- classic_mod_54188_summary[4221:4225, 1:2]
B_custom <- custom_mod_54188_summary[4234:4238, 1:2]
Phi_classic <- classic_mod_54188_summary[4240:4243, 1:2]
Phi_custom <- custom_mod_54188_summary[4253:4256, 1:2]
p_classic <- classic_mod_54188_summary[4226:4239, 1:2]
p_custom <- custom_mod_54188_summary[4239:4252, 1:2]
  
GenQuant_comparison <- bind_rows(
  left_join(N_classic, N_custom, by = "variable", suffix = c("_classic", "_custom")) %>% mutate(parameter = "abundance"),
  left_join(B_classic, B_custom, by = "variable", suffix = c("_classic", "_custom")) %>% mutate(parameter = "recruitment"),
  left_join(Phi_classic, Phi_custom, by = "variable", suffix = c("_classic", "_custom")) %>% mutate(parameter = "survival"),
  left_join(p_classic, p_custom, by = "variable", suffix = c("_classic", "_custom")) %>% mutate(parameter = "detection"),
) %>% 
  select(variable, parameter, everything())

print(GenQuant_comparison)

```

**Visually compare abundance and recruitment estimates between models**

Note that axes are not standardized.

```{r}
# visual comparison of abundance and recruitment plots
abund_recruit_comparison_plot_54188 <- ggarrange(classic_annotated, custom_annotated, ncol=2)
print(abund_recruit_comparison_plot_54188)
```

#### Model Fit

Use leave-one-out (LOO) cross-validation, a standard method to calculate the predictive accuracy of Bayesian models, to compare how well the classic and custom models fit the Trapdoor data. The cmdstanr package has built in LOO capabilities. Briefly,

-   LOO cross-validation uses log likelihood values, which now appear in the model summary as generated quantities, to evaluate how well the model predicts each data point when that point is left out of the fitting process. Likelihood, calculated at the individual level, is the probability of observing the data (in this case, an individual frog's capture history) given the model parameters.

The loo( ) function generates an expected log predictive density (elpd) value for each model. The loo_compare( ) function ranks models based on their elpd values, with the best fit listed first, and calculates the difference in those values. A difference of more than 2x the standard error is generally considered significant in a LOO comparison.

```{r}
loo_classic <- classic_mod_54188$m_fit$loo()

loo_custom <- custom_mod_54188$m_fit$loo()

loo_compare <- loo::loo_compare(loo_classic, loo_custom)

print(loo_compare)

# extract elpd_diff and se_diff for model1
elpd_diff_model1 <- loo_compare["model1", "elpd_diff"]
se_diff_model1 <- loo_compare["model1", "se_diff"]

# calculate significance ratio
result <- elpd_diff_model1 / se_diff_model1

# interpret
if (abs(result) > 2) {
  cat("Result of elpd_diff / se_diff for model1:", result, "\n")
  cat("The custom model fits the data significantly better than the classic model.\n")
} else {
  cat("Result of elpd_diff / se_diff for model1:", result, "\n")
  cat("The custom model does not fit the data significantly better than the classic model.\n")
}

```
